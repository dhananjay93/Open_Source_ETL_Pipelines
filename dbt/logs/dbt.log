[0m17:57:44.927076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063edf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106417410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106417b10>]}


============================== 17:57:44.930416 | 0249eff9-610d-46d5-9230-daf856300241 ==============================
[0m17:57:44.930416 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:57:44.930742 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'quiet': 'False', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'indirect_selection': 'eager', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'partial_parse': 'True', 'cache_selected_only': 'False', 'version_check': 'True', 'empty': 'None', 'invocation_command': 'dbt debug', 'log_format': 'default', 'use_colors': 'True', 'warn_error': 'None', 'static_parser': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'debug': 'False', 'write_json': 'True'}
[0m17:57:44.944957 [info ] [MainThread]: dbt version: 1.10.10
[0m17:57:44.945179 [info ] [MainThread]: python version: 3.11.5
[0m17:57:44.945343 [info ] [MainThread]: python path: /Users/dhananjayhawal/anaconda3/bin/python
[0m17:57:44.945483 [info ] [MainThread]: os info: macOS-15.6-arm64-arm-64bit
[0m17:57:45.226601 [info ] [MainThread]: Using profiles dir at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt
[0m17:57:45.226919 [info ] [MainThread]: Using profiles.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/profiles.yml
[0m17:57:45.227094 [info ] [MainThread]: Using dbt_project.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml
[0m17:57:45.227543 [info ] [MainThread]: adapter type: postgres
[0m17:57:45.227748 [info ] [MainThread]: adapter version: 1.8.2
[0m17:57:45.292241 [info ] [MainThread]: Configuration:
[0m17:57:45.292575 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:57:45.292723 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:57:45.292854 [info ] [MainThread]: Required dependencies:
[0m17:57:45.293297 [debug] [MainThread]: Executing "git --help"
[0m17:57:45.324651 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:57:45.325275 [debug] [MainThread]: STDERR: "b''"
[0m17:57:45.325464 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:57:45.325644 [info ] [MainThread]: Connection:
[0m17:57:45.325819 [info ] [MainThread]:   host: postgres
[0m17:57:45.325978 [info ] [MainThread]:   port: 5432
[0m17:57:45.326175 [info ] [MainThread]:   user: postgres
[0m17:57:45.326307 [info ] [MainThread]:   database: staging
[0m17:57:45.326429 [info ] [MainThread]:   schema: public
[0m17:57:45.326545 [info ] [MainThread]:   connect_timeout: 10
[0m17:57:45.326663 [info ] [MainThread]:   role: None
[0m17:57:45.326781 [info ] [MainThread]:   search_path: None
[0m17:57:45.326891 [info ] [MainThread]:   keepalives_idle: 0
[0m17:57:45.327003 [info ] [MainThread]:   sslmode: None
[0m17:57:45.327116 [info ] [MainThread]:   sslcert: None
[0m17:57:45.327230 [info ] [MainThread]:   sslkey: None
[0m17:57:45.327342 [info ] [MainThread]:   sslrootcert: None
[0m17:57:45.327459 [info ] [MainThread]:   application_name: dbt
[0m17:57:45.327568 [info ] [MainThread]:   retries: 1
[0m17:57:45.327882 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:57:45.387258 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m17:57:45.468458 [debug] [MainThread]: Using postgres connection "debug"
[0m17:57:45.468731 [debug] [MainThread]: On debug: select 1 as id
[0m17:57:45.468863 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:57:45.595930 [debug] [MainThread]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
could not translate host name "postgres" to address: nodename nor servname provided, or not known

[0m17:57:45.599077 [debug] [MainThread]: Postgres adapter: Error running SQL: select 1 as id
[0m17:57:45.599222 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m17:57:45.599407 [debug] [MainThread]: On debug: No close available on handle
[0m17:57:45.599613 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m17:57:45.599798 [info ] [MainThread]: [31m1 check failed:[0m
[0m17:57:45.599931 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Database Error
  could not translate host name "postgres" to address: nodename nor servname provided, or not known
  

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m17:57:45.624680 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.7534907, "process_in_blocks": "0", "process_kernel_time": 0.292686, "process_mem_max_rss": "120782848", "process_out_blocks": "0", "process_user_time": 0.819974}
[0m17:57:45.625165 [debug] [MainThread]: Command `dbt debug` failed at 17:57:45.625092 after 0.75 seconds
[0m17:57:45.625420 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:57:45.625662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101010f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10636fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a11050>]}
[0m17:57:45.625953 [debug] [MainThread]: Flushing usage events
[0m17:57:47.441412 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:59:17.286886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115b8f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077f3e90>]}


============================== 17:59:17.290164 | 0f0a6e3c-0553-4dea-8b64-ca8f428840d7 ==============================
[0m17:59:17.290164 [info ] [MainThread]: Running with dbt=1.10.10
[0m17:59:17.290496 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'None', 'warn_error': 'None', 'log_format': 'default', 'write_json': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'partial_parse': 'True', 'introspect': 'True', 'static_parser': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'fail_fast': 'False', 'log_cache_events': 'False', 'debug': 'False', 'invocation_command': 'dbt debug', 'version_check': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:59:17.304961 [info ] [MainThread]: dbt version: 1.10.10
[0m17:59:17.305269 [info ] [MainThread]: python version: 3.11.5
[0m17:59:17.305464 [info ] [MainThread]: python path: /Users/dhananjayhawal/anaconda3/bin/python
[0m17:59:17.305611 [info ] [MainThread]: os info: macOS-15.6-arm64-arm-64bit
[0m17:59:17.362750 [info ] [MainThread]: Using profiles dir at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt
[0m17:59:17.363077 [info ] [MainThread]: Using profiles.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/profiles.yml
[0m17:59:17.363228 [info ] [MainThread]: Using dbt_project.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml
[0m17:59:17.363830 [info ] [MainThread]: adapter type: postgres
[0m17:59:17.364006 [info ] [MainThread]: adapter version: 1.8.2
[0m17:59:17.420880 [info ] [MainThread]: Configuration:
[0m17:59:17.421216 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:59:17.421379 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:59:17.421511 [info ] [MainThread]: Required dependencies:
[0m17:59:17.421968 [debug] [MainThread]: Executing "git --help"
[0m17:59:17.459688 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:59:17.460388 [debug] [MainThread]: STDERR: "b''"
[0m17:59:17.460578 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:59:17.460773 [info ] [MainThread]: Connection:
[0m17:59:17.460957 [info ] [MainThread]:   host: localhost
[0m17:59:17.461183 [info ] [MainThread]:   port: 5432
[0m17:59:17.461349 [info ] [MainThread]:   user: postgres
[0m17:59:17.461478 [info ] [MainThread]:   database: staging
[0m17:59:17.461606 [info ] [MainThread]:   schema: public
[0m17:59:17.461730 [info ] [MainThread]:   connect_timeout: 10
[0m17:59:17.461852 [info ] [MainThread]:   role: None
[0m17:59:17.461974 [info ] [MainThread]:   search_path: None
[0m17:59:17.462094 [info ] [MainThread]:   keepalives_idle: 0
[0m17:59:17.462215 [info ] [MainThread]:   sslmode: None
[0m17:59:17.462334 [info ] [MainThread]:   sslcert: None
[0m17:59:17.462446 [info ] [MainThread]:   sslkey: None
[0m17:59:17.462568 [info ] [MainThread]:   sslrootcert: None
[0m17:59:17.462688 [info ] [MainThread]:   application_name: dbt
[0m17:59:17.462799 [info ] [MainThread]:   retries: 1
[0m17:59:17.463265 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m17:59:17.515707 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m17:59:17.562370 [debug] [MainThread]: Using postgres connection "debug"
[0m17:59:17.562612 [debug] [MainThread]: On debug: select 1 as id
[0m17:59:17.562757 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:59:17.679562 [debug] [MainThread]: SQL status: SELECT 1 in 0.117 seconds
[0m17:59:17.680246 [debug] [MainThread]: On debug: Close
[0m17:59:17.680460 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:59:17.680650 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:59:17.683351 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.453213, "process_in_blocks": "0", "process_kernel_time": 0.270062, "process_mem_max_rss": "125337600", "process_out_blocks": "0", "process_user_time": 0.815737}
[0m17:59:17.683735 [debug] [MainThread]: Command `dbt debug` succeeded at 17:59:17.683677 after 0.45 seconds
[0m17:59:17.683928 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:59:17.684133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153d210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11153e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121e9690>]}
[0m17:59:17.684361 [debug] [MainThread]: Flushing usage events
[0m17:59:19.394135 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:01:26.768407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099608d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099cfe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099ffd50>]}


============================== 18:01:26.771818 | 475fe407-546f-4647-98d8-b627a0aa05a2 ==============================
[0m18:01:26.771818 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:01:26.772149 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'no_print': 'None', 'warn_error': 'None', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'invocation_command': 'dbt run', 'fail_fast': 'False', 'version_check': 'True', 'empty': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'log_format': 'default'}
[0m18:01:27.180739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109961f50>]}
[0m18:01:27.215312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719c090>]}
[0m18:01:27.216122 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:01:27.267277 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:01:27.268034 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m18:01:27.268276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099dab10>]}
[0m18:01:27.741568 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.elt_assignment.gold
[0m18:01:27.744369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6c1c10>]}
[0m18:01:27.773061 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:01:27.775150 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:01:27.790918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10997d010>]}
[0m18:01:27.791223 [info ] [MainThread]: Found 2 models, 433 macros
[0m18:01:27.791387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f4da50>]}
[0m18:01:27.792052 [info ] [MainThread]: 
[0m18:01:27.792232 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:01:27.792362 [info ] [MainThread]: 
[0m18:01:27.792596 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:01:27.794492 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:01:27.794836 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:01:27.879224 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:01:27.879549 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:01:27.879806 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:01:27.880012 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:01:27.880175 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:27.880320 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:01:27.918247 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.038 seconds
[0m18:01:27.918490 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.038 seconds
[0m18:01:27.919189 [debug] [ThreadPool]: On list_staging: Close
[0m18:01:27.919690 [debug] [ThreadPool]: On list_staging: Close
[0m18:01:27.920149 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_public_bronze)
[0m18:01:27.920374 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "public_bronze"
"
[0m18:01:27.922901 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:01:27.923079 [debug] [ThreadPool]: On create_staging_public_bronze: BEGIN
[0m18:01:27.923397 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_public_silver)
[0m18:01:27.923573 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:01:27.923763 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "public_silver"
"
[0m18:01:27.924948 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:01:27.925127 [debug] [ThreadPool]: On create_staging_public_silver: BEGIN
[0m18:01:27.925253 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:01:27.931992 [debug] [ThreadPool]: SQL status: BEGIN in 0.008 seconds
[0m18:01:27.932163 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:01:27.932293 [debug] [ThreadPool]: On create_staging_public_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "create_staging_public_bronze"} */
create schema if not exists "public_bronze"
[0m18:01:27.933169 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m18:01:27.933756 [debug] [ThreadPool]: On create_staging_public_bronze: COMMIT
[0m18:01:27.933957 [debug] [ThreadPool]: SQL status: BEGIN in 0.009 seconds
[0m18:01:27.934235 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:01:27.934390 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:01:27.934528 [debug] [ThreadPool]: On create_staging_public_bronze: COMMIT
[0m18:01:27.934725 [debug] [ThreadPool]: On create_staging_public_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "create_staging_public_silver"} */
create schema if not exists "public_silver"
[0m18:01:27.935687 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m18:01:27.936163 [debug] [ThreadPool]: On create_staging_public_silver: COMMIT
[0m18:01:27.936318 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:01:27.936473 [debug] [ThreadPool]: On create_staging_public_silver: COMMIT
[0m18:01:27.936660 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m18:01:27.936826 [debug] [ThreadPool]: On create_staging_public_bronze: Close
[0m18:01:27.937389 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m18:01:27.937623 [debug] [ThreadPool]: On create_staging_public_silver: Close
[0m18:01:27.938367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_staging_public_silver, now list_staging_public_bronze)
[0m18:01:27.941122 [debug] [ThreadPool]: Using postgres connection "list_staging_public_bronze"
[0m18:01:27.941442 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_staging_public_bronze, now list_staging_public_silver)
[0m18:01:27.941694 [debug] [ThreadPool]: On list_staging_public_bronze: BEGIN
[0m18:01:27.942784 [debug] [ThreadPool]: Using postgres connection "list_staging_public_silver"
[0m18:01:27.942937 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:01:27.943066 [debug] [ThreadPool]: On list_staging_public_silver: BEGIN
[0m18:01:27.943302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:01:27.954104 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:01:27.954395 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:01:27.954630 [debug] [ThreadPool]: Using postgres connection "list_staging_public_bronze"
[0m18:01:27.954880 [debug] [ThreadPool]: Using postgres connection "list_staging_public_silver"
[0m18:01:27.955101 [debug] [ThreadPool]: On list_staging_public_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_public_bronze"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_bronze'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_bronze'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_bronze'
  
[0m18:01:27.955334 [debug] [ThreadPool]: On list_staging_public_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_public_silver"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_silver'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_silver'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_silver'
  
[0m18:01:27.958395 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m18:01:27.958644 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m18:01:27.959308 [debug] [ThreadPool]: On list_staging_public_silver: ROLLBACK
[0m18:01:27.959883 [debug] [ThreadPool]: On list_staging_public_bronze: ROLLBACK
[0m18:01:27.960421 [debug] [ThreadPool]: On list_staging_public_bronze: Close
[0m18:01:27.960598 [debug] [ThreadPool]: On list_staging_public_silver: Close
[0m18:01:27.963162 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:27.963369 [debug] [MainThread]: On master: BEGIN
[0m18:01:27.963504 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:01:27.970418 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m18:01:27.970660 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:27.970875 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:01:27.976792 [debug] [MainThread]: SQL status: SELECT 29 in 0.006 seconds
[0m18:01:27.977693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086b1210>]}
[0m18:01:27.977945 [debug] [MainThread]: On master: ROLLBACK
[0m18:01:27.978529 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:27.978686 [debug] [MainThread]: On master: BEGIN
[0m18:01:27.979533 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:01:27.979678 [debug] [MainThread]: On master: COMMIT
[0m18:01:27.979800 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:27.979913 [debug] [MainThread]: On master: COMMIT
[0m18:01:27.980347 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:01:27.980483 [debug] [MainThread]: On master: Close
[0m18:01:27.984831 [debug] [Thread-1 (]: Began running node model.elt_assignment.customers_clean
[0m18:01:27.985362 [info ] [Thread-1 (]: 1 of 2 START sql table model public_silver.customers_clean ..................... [RUN]
[0m18:01:27.986101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_public_bronze, now model.elt_assignment.customers_clean)
[0m18:01:27.986567 [debug] [Thread-2 (]: Began running node model.elt_assignment.customers_raw
[0m18:01:27.987211 [debug] [Thread-1 (]: Began compiling node model.elt_assignment.customers_clean
[0m18:01:27.987943 [info ] [Thread-2 (]: 2 of 2 START sql table model public_bronze.customers_raw ....................... [RUN]
[0m18:01:27.991711 [debug] [Thread-1 (]: Writing injected SQL for node "model.elt_assignment.customers_clean"
[0m18:01:27.992294 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_staging_public_silver, now model.elt_assignment.customers_raw)
[0m18:01:27.993166 [debug] [Thread-2 (]: Began compiling node model.elt_assignment.customers_raw
[0m18:01:27.994168 [debug] [Thread-2 (]: Writing injected SQL for node "model.elt_assignment.customers_raw"
[0m18:01:27.996331 [debug] [Thread-2 (]: Began executing node model.elt_assignment.customers_raw
[0m18:01:28.009744 [debug] [Thread-1 (]: Began executing node model.elt_assignment.customers_clean
[0m18:01:28.015935 [debug] [Thread-2 (]: Writing runtime sql for node "model.elt_assignment.customers_raw"
[0m18:01:28.017892 [debug] [Thread-1 (]: Writing runtime sql for node "model.elt_assignment.customers_clean"
[0m18:01:28.019916 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:01:28.020111 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: BEGIN
[0m18:01:28.020267 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m18:01:28.020534 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:01:28.020711 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: BEGIN
[0m18:01:28.020859 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:01:28.033804 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m18:01:28.034146 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m18:01:28.034412 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:01:28.034583 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:01:28.034748 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */

  
    

  create  table "staging"."public_bronze"."customers_raw__dbt_tmp"
  
  
    as
  
  (
    -- Reference table created directly by Airflow/SQL COPY
-- dbt will just treat this as a source, not transform
select * from bronze.customers_raw
  );
  
[0m18:01:28.035061 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */

  
    

  create  table "staging"."public_silver"."customers_clean__dbt_tmp"
  
  
    as
  
  (
    WITH b AS (
  SELECT
    customerid,
    age,
    gender,
    tenure,
    monthlycharges,
    contracttype,
    internetservice,
    totalcharges,
    techsupport,
    churn
  FROM bronze.customers_raw
)
SELECT
  md5((customerid)::text) AS customer_hash,
  COALESCE(NULLIF(LOWER(gender), ''), 'unknown')   AS gender,
  COALESCE((age)::int, 0)                          AS age,
  GREATEST(COALESCE((tenure)::int, 0), 0)          AS tenure_months,
  COALESCE((monthlycharges)::numeric(10,2), 0.00)  AS monthly_charges,
  COALESCE(NULLIF(contracttype, ''), 'Unknown')    AS contract_type,
  COALESCE(NULLIF(internetservice, ''), 'Unknown') AS internet_service,
  COALESCE((totalcharges)::numeric(12,2), 0.00)    AS total_charges,
  CASE 
    WHEN LOWER(COALESCE(techsupport, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(techsupport, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS has_tech_support,
  CASE 
    WHEN LOWER(COALESCE(churn, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(churn, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS is_churned,
  CURRENT_TIMESTAMP                                  AS _loaded_at
FROM b
  );
  
[0m18:01:28.039266 [debug] [Thread-2 (]: SQL status: SELECT 1000 in 0.004 seconds
[0m18:01:28.044220 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:01:28.044424 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m18:01:28.044626 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."public_bronze"."customers_raw__dbt_tmp" rename to "customers_raw"
[0m18:01:28.046111 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:01:28.046356 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
alter table "staging"."public_silver"."customers_clean__dbt_tmp" rename to "customers_clean"
[0m18:01:28.046938 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:01:28.047177 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:01:28.053716 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:01:28.054371 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:01:28.054559 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:01:28.054716 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:01:28.054861 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:01:28.055007 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:01:28.058625 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m18:01:28.061422 [debug] [Thread-1 (]: Applying DROP to: "staging"."public_silver"."customers_clean__dbt_backup"
[0m18:01:28.063542 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:01:28.063715 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m18:01:28.063907 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
drop table if exists "staging"."public_silver"."customers_clean__dbt_backup" cascade
[0m18:01:28.064977 [debug] [Thread-2 (]: Applying DROP to: "staging"."public_bronze"."customers_raw__dbt_backup"
[0m18:01:28.065351 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:01:28.065521 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
drop table if exists "staging"."public_bronze"."customers_raw__dbt_backup" cascade
[0m18:01:28.065697 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m18:01:28.066820 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: Close
[0m18:01:28.067006 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m18:01:28.068236 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: Close
[0m18:01:28.069098 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab27f50>]}
[0m18:01:28.069475 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_silver.customers_clean ................ [[32mSELECT 1000[0m in 0.08s]
[0m18:01:28.069725 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '475fe407-546f-4647-98d8-b627a0aa05a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a739690>]}
[0m18:01:28.070017 [debug] [Thread-1 (]: Finished running node model.elt_assignment.customers_clean
[0m18:01:28.070337 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_bronze.customers_raw .................. [[32mSELECT 1000[0m in 0.08s]
[0m18:01:28.070632 [debug] [Thread-2 (]: Finished running node model.elt_assignment.customers_raw
[0m18:01:28.071317 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:28.071501 [debug] [MainThread]: On master: BEGIN
[0m18:01:28.071627 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:01:28.078376 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m18:01:28.078561 [debug] [MainThread]: On master: COMMIT
[0m18:01:28.078699 [debug] [MainThread]: Using postgres connection "master"
[0m18:01:28.078821 [debug] [MainThread]: On master: COMMIT
[0m18:01:28.079335 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:01:28.079459 [debug] [MainThread]: On master: Close
[0m18:01:28.079639 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:01:28.079759 [debug] [MainThread]: Connection 'model.elt_assignment.customers_clean' was properly closed.
[0m18:01:28.079874 [debug] [MainThread]: Connection 'model.elt_assignment.customers_raw' was properly closed.
[0m18:01:28.080036 [info ] [MainThread]: 
[0m18:01:28.080184 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 0.29 seconds (0.29s).
[0m18:01:28.080521 [debug] [MainThread]: Command end result
[0m18:01:28.091176 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:01:28.093463 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:01:28.099062 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/run_results.json
[0m18:01:28.099349 [info ] [MainThread]: 
[0m18:01:28.099548 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:01:28.100301 [info ] [MainThread]: 
[0m18:01:28.100544 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m18:01:28.104570 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3864378, "process_in_blocks": "0", "process_kernel_time": 0.385907, "process_mem_max_rss": "139051008", "process_out_blocks": "0", "process_user_time": 1.491303}
[0m18:01:28.104962 [debug] [MainThread]: Command `dbt run` succeeded at 18:01:28.104915 after 1.39 seconds
[0m18:01:28.105171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099ffe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099ffd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105920f50>]}
[0m18:01:28.105369 [debug] [MainThread]: Flushing usage events
[0m18:01:29.961283 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:15.038077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f03350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f7cad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f779d0>]}


============================== 18:03:15.041418 | 89eda4cc-79a1-4816-b07d-c982308911ed ==============================
[0m18:03:15.041418 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:03:15.041746 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'partial_parse': 'True', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'cache_selected_only': 'False', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'quiet': 'False', 'static_parser': 'True', 'empty': 'None', 'introspect': 'True', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'log_format': 'default', 'debug': 'False'}
[0m18:03:15.055098 [info ] [MainThread]: dbt version: 1.10.10
[0m18:03:15.055336 [info ] [MainThread]: python version: 3.11.5
[0m18:03:15.055503 [info ] [MainThread]: python path: /Users/dhananjayhawal/anaconda3/bin/python
[0m18:03:15.055650 [info ] [MainThread]: os info: macOS-15.6-arm64-arm-64bit
[0m18:03:15.107194 [info ] [MainThread]: Using profiles dir at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt
[0m18:03:15.107513 [info ] [MainThread]: Using profiles.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/profiles.yml
[0m18:03:15.107668 [info ] [MainThread]: Using dbt_project.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml
[0m18:03:15.108289 [info ] [MainThread]: adapter type: postgres
[0m18:03:15.108480 [info ] [MainThread]: adapter version: 1.8.2
[0m18:03:15.110106 [info ] [MainThread]: Configuration:
[0m18:03:15.110276 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:03:15.110408 [info ] [MainThread]:   dbt_project.yml file [[31mERROR invalid[0m]
[0m18:03:15.110533 [info ] [MainThread]: Required dependencies:
[0m18:03:15.110783 [debug] [MainThread]: Executing "git --help"
[0m18:03:15.143988 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:03:15.144595 [debug] [MainThread]: STDERR: "b''"
[0m18:03:15.144789 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:03:15.144966 [info ] [MainThread]: Connection:
[0m18:03:15.145133 [info ] [MainThread]:   host: localhost
[0m18:03:15.145255 [info ] [MainThread]:   port: 5432
[0m18:03:15.145366 [info ] [MainThread]:   user: postgres
[0m18:03:15.145479 [info ] [MainThread]:   database: staging
[0m18:03:15.145587 [info ] [MainThread]:   schema: public
[0m18:03:15.145696 [info ] [MainThread]:   connect_timeout: 10
[0m18:03:15.145808 [info ] [MainThread]:   role: None
[0m18:03:15.145922 [info ] [MainThread]:   search_path: None
[0m18:03:15.146029 [info ] [MainThread]:   keepalives_idle: 0
[0m18:03:15.146135 [info ] [MainThread]:   sslmode: None
[0m18:03:15.146258 [info ] [MainThread]:   sslcert: None
[0m18:03:15.146363 [info ] [MainThread]:   sslkey: None
[0m18:03:15.146472 [info ] [MainThread]:   sslrootcert: None
[0m18:03:15.146581 [info ] [MainThread]:   application_name: dbt
[0m18:03:15.146692 [info ] [MainThread]:   retries: 1
[0m18:03:15.146987 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:03:15.194947 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m18:03:15.241327 [debug] [MainThread]: Using postgres connection "debug"
[0m18:03:15.241590 [debug] [MainThread]: On debug: select 1 as id
[0m18:03:15.241738 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:15.276014 [debug] [MainThread]: SQL status: SELECT 1 in 0.034 seconds
[0m18:03:15.276593 [debug] [MainThread]: On debug: Close
[0m18:03:15.276774 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:03:15.276940 [info ] [MainThread]: [31m1 check failed:[0m
[0m18:03:15.277076 [info ] [MainThread]: Project loading failed for the following reason:
Runtime Error
  Required "name" field not present in project

Error encountered in /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml


[0m18:03:15.279378 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.29338762, "process_in_blocks": "0", "process_kernel_time": 0.259869, "process_mem_max_rss": "123371520", "process_out_blocks": "0", "process_user_time": 0.731243}
[0m18:03:15.279698 [debug] [MainThread]: Command `dbt debug` failed at 18:03:15.279643 after 0.29 seconds
[0m18:03:15.279880 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:03:15.280056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101049090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10710e9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074e5b50>]}
[0m18:03:15.280248 [debug] [MainThread]: Flushing usage events
[0m18:03:17.173074 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:03:45.286773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ddbbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e29450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e7bb50>]}


============================== 18:03:45.290082 | 5527fba8-fe53-4be1-850a-028af4d48e2c ==============================
[0m18:03:45.290082 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:03:45.290476 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'use_colors': 'True', 'static_parser': 'True', 'log_format': 'default', 'use_experimental_parser': 'False', 'printer_width': '80', 'invocation_command': 'dbt debug', 'debug': 'False', 'quiet': 'False', 'cache_selected_only': 'False', 'partial_parse': 'True', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'empty': 'None', 'version_check': 'True', 'target_path': 'None', 'write_json': 'True', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True'}
[0m18:03:45.301220 [info ] [MainThread]: dbt version: 1.10.10
[0m18:03:45.301531 [info ] [MainThread]: python version: 3.11.5
[0m18:03:45.301709 [info ] [MainThread]: python path: /Users/dhananjayhawal/anaconda3/bin/python
[0m18:03:45.301852 [info ] [MainThread]: os info: macOS-15.6-arm64-arm-64bit
[0m18:03:45.354666 [info ] [MainThread]: Using profiles dir at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt
[0m18:03:45.355038 [info ] [MainThread]: Using profiles.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/profiles.yml
[0m18:03:45.355197 [info ] [MainThread]: Using dbt_project.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml
[0m18:03:45.355759 [info ] [MainThread]: adapter type: postgres
[0m18:03:45.355941 [info ] [MainThread]: adapter version: 1.8.2
[0m18:03:45.413822 [info ] [MainThread]: Configuration:
[0m18:03:45.414160 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:03:45.414303 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:03:45.414431 [info ] [MainThread]: Required dependencies:
[0m18:03:45.414894 [debug] [MainThread]: Executing "git --help"
[0m18:03:45.455253 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:03:45.456453 [debug] [MainThread]: STDERR: "b''"
[0m18:03:45.456742 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:03:45.456985 [info ] [MainThread]: Connection:
[0m18:03:45.457192 [info ] [MainThread]:   host: localhost
[0m18:03:45.457322 [info ] [MainThread]:   port: 5432
[0m18:03:45.457448 [info ] [MainThread]:   user: postgres
[0m18:03:45.457569 [info ] [MainThread]:   database: staging
[0m18:03:45.457684 [info ] [MainThread]:   schema: public
[0m18:03:45.457796 [info ] [MainThread]:   connect_timeout: 10
[0m18:03:45.457914 [info ] [MainThread]:   role: None
[0m18:03:45.458027 [info ] [MainThread]:   search_path: None
[0m18:03:45.458136 [info ] [MainThread]:   keepalives_idle: 0
[0m18:03:45.458252 [info ] [MainThread]:   sslmode: None
[0m18:03:45.458542 [info ] [MainThread]:   sslcert: None
[0m18:03:45.458740 [info ] [MainThread]:   sslkey: None
[0m18:03:45.458875 [info ] [MainThread]:   sslrootcert: None
[0m18:03:45.459017 [info ] [MainThread]:   application_name: dbt
[0m18:03:45.459137 [info ] [MainThread]:   retries: 1
[0m18:03:45.459537 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:03:45.508355 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m18:03:45.565932 [debug] [MainThread]: Using postgres connection "debug"
[0m18:03:45.566196 [debug] [MainThread]: On debug: select 1 as id
[0m18:03:45.566347 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:03:45.601847 [debug] [MainThread]: SQL status: SELECT 1 in 0.035 seconds
[0m18:03:45.602402 [debug] [MainThread]: On debug: Close
[0m18:03:45.602581 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:03:45.602741 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:03:45.604895 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.3736455, "process_in_blocks": "0", "process_kernel_time": 0.256725, "process_mem_max_rss": "123305984", "process_out_blocks": "0", "process_user_time": 0.806359}
[0m18:03:45.605221 [debug] [MainThread]: Command `dbt debug` succeeded at 18:03:45.605167 after 0.37 seconds
[0m18:03:45.605389 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:03:45.605565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d25090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ad3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10993dc50>]}
[0m18:03:45.605754 [debug] [MainThread]: Flushing usage events
[0m18:03:47.213757 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:04:45.749639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057878d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105816e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105817510>]}


============================== 18:04:45.753007 | d9e0503d-ae4a-4faf-aaad-6aee26304514 ==============================
[0m18:04:45.753007 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:04:45.753337 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'use_colors': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'quiet': 'False', 'version_check': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'use_experimental_parser': 'False', 'no_print': 'None', 'printer_width': '80', 'empty': 'False'}
[0m18:04:46.076140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d3bb90>]}
[0m18:04:46.110456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fbcf50>]}
[0m18:04:46.111377 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:04:46.167896 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:04:46.209010 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m18:04:46.209342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044e8710>]}
[0m18:04:46.648996 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.elt_assignment.gold
[0m18:04:46.651194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036a0f50>]}
[0m18:04:46.677334 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:04:46.679446 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:04:46.695429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106628450>]}
[0m18:04:46.695726 [info ] [MainThread]: Found 2 models, 433 macros
[0m18:04:46.695897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057b5f50>]}
[0m18:04:46.696560 [info ] [MainThread]: 
[0m18:04:46.696722 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:04:46.696856 [info ] [MainThread]: 
[0m18:04:46.697093 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:04:46.698934 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:04:46.699264 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:04:46.764962 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:04:46.765179 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:04:46.765373 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:04:46.765528 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:04:46.765670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:04:46.765799 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:04:46.805448 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.040 seconds
[0m18:04:46.805682 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.040 seconds
[0m18:04:46.806425 [debug] [ThreadPool]: On list_staging: Close
[0m18:04:46.807016 [debug] [ThreadPool]: On list_staging: Close
[0m18:04:46.807512 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_public_bronze)
[0m18:04:46.807711 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now create_staging_public_silver)
[0m18:04:46.807951 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "public_bronze"
"
[0m18:04:46.808175 [debug] [ThreadPool]: Creating schema "database: "staging"
schema: "public_silver"
"
[0m18:04:46.810825 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:04:46.811828 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:04:46.811972 [debug] [ThreadPool]: On create_staging_public_bronze: BEGIN
[0m18:04:46.812107 [debug] [ThreadPool]: On create_staging_public_silver: BEGIN
[0m18:04:46.812225 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:04:46.812353 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:04:46.823016 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.823352 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:04:46.823555 [debug] [ThreadPool]: On create_staging_public_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "create_staging_public_silver"} */
create schema if not exists "public_silver"
[0m18:04:46.823737 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.823920 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:04:46.824061 [debug] [ThreadPool]: On create_staging_public_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "create_staging_public_bronze"} */
create schema if not exists "public_bronze"
[0m18:04:46.824369 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m18:04:46.824951 [debug] [ThreadPool]: On create_staging_public_silver: COMMIT
[0m18:04:46.825129 [debug] [ThreadPool]: Using postgres connection "create_staging_public_silver"
[0m18:04:46.825256 [debug] [ThreadPool]: On create_staging_public_silver: COMMIT
[0m18:04:46.825406 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m18:04:46.825840 [debug] [ThreadPool]: On create_staging_public_bronze: COMMIT
[0m18:04:46.826072 [debug] [ThreadPool]: Using postgres connection "create_staging_public_bronze"
[0m18:04:46.826262 [debug] [ThreadPool]: On create_staging_public_bronze: COMMIT
[0m18:04:46.826433 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m18:04:46.826583 [debug] [ThreadPool]: On create_staging_public_silver: Close
[0m18:04:46.826999 [debug] [ThreadPool]: SQL status: COMMIT in 0.001 seconds
[0m18:04:46.827143 [debug] [ThreadPool]: On create_staging_public_bronze: Close
[0m18:04:46.827774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_staging_public_silver, now list_staging_public_bronze)
[0m18:04:46.828001 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_staging_public_bronze, now list_staging_public_silver)
[0m18:04:46.831011 [debug] [ThreadPool]: Using postgres connection "list_staging_public_bronze"
[0m18:04:46.832191 [debug] [ThreadPool]: Using postgres connection "list_staging_public_silver"
[0m18:04:46.832370 [debug] [ThreadPool]: On list_staging_public_bronze: BEGIN
[0m18:04:46.832492 [debug] [ThreadPool]: On list_staging_public_silver: BEGIN
[0m18:04:46.832620 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:04:46.832738 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:04:46.843643 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.843859 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.844102 [debug] [ThreadPool]: Using postgres connection "list_staging_public_silver"
[0m18:04:46.844230 [debug] [ThreadPool]: Using postgres connection "list_staging_public_bronze"
[0m18:04:46.844379 [debug] [ThreadPool]: On list_staging_public_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_public_silver"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_silver'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_silver'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_silver'
  
[0m18:04:46.844541 [debug] [ThreadPool]: On list_staging_public_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_public_bronze"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_bronze'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_bronze'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_bronze'
  
[0m18:04:46.847400 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m18:04:46.847611 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m18:04:46.848250 [debug] [ThreadPool]: On list_staging_public_bronze: ROLLBACK
[0m18:04:46.848725 [debug] [ThreadPool]: On list_staging_public_silver: ROLLBACK
[0m18:04:46.849169 [debug] [ThreadPool]: On list_staging_public_bronze: Close
[0m18:04:46.849330 [debug] [ThreadPool]: On list_staging_public_silver: Close
[0m18:04:46.851693 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.851867 [debug] [MainThread]: On master: BEGIN
[0m18:04:46.851983 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:04:46.858409 [debug] [MainThread]: SQL status: BEGIN in 0.006 seconds
[0m18:04:46.858624 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.858820 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:04:46.866213 [debug] [MainThread]: SQL status: SELECT 29 in 0.007 seconds
[0m18:04:46.867077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ddad50>]}
[0m18:04:46.867350 [debug] [MainThread]: On master: ROLLBACK
[0m18:04:46.867789 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.867929 [debug] [MainThread]: On master: BEGIN
[0m18:04:46.868641 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:04:46.868887 [debug] [MainThread]: On master: COMMIT
[0m18:04:46.869037 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.869166 [debug] [MainThread]: On master: COMMIT
[0m18:04:46.869591 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:04:46.869772 [debug] [MainThread]: On master: Close
[0m18:04:46.872477 [debug] [Thread-1 (]: Began running node model.elt_assignment.customers_clean
[0m18:04:46.872681 [debug] [Thread-2 (]: Began running node model.elt_assignment.customers_raw
[0m18:04:46.872962 [info ] [Thread-1 (]: 1 of 2 START sql table model public_silver.customers_clean ..................... [RUN]
[0m18:04:46.873229 [info ] [Thread-2 (]: 2 of 2 START sql table model public_bronze.customers_raw ....................... [RUN]
[0m18:04:46.873495 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_public_bronze, now model.elt_assignment.customers_clean)
[0m18:04:46.873740 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_staging_public_silver, now model.elt_assignment.customers_raw)
[0m18:04:46.873938 [debug] [Thread-1 (]: Began compiling node model.elt_assignment.customers_clean
[0m18:04:46.874092 [debug] [Thread-2 (]: Began compiling node model.elt_assignment.customers_raw
[0m18:04:46.877294 [debug] [Thread-1 (]: Writing injected SQL for node "model.elt_assignment.customers_clean"
[0m18:04:46.878213 [debug] [Thread-2 (]: Writing injected SQL for node "model.elt_assignment.customers_raw"
[0m18:04:46.879045 [debug] [Thread-1 (]: Began executing node model.elt_assignment.customers_clean
[0m18:04:46.891005 [debug] [Thread-2 (]: Began executing node model.elt_assignment.customers_raw
[0m18:04:46.898243 [debug] [Thread-1 (]: Writing runtime sql for node "model.elt_assignment.customers_clean"
[0m18:04:46.900050 [debug] [Thread-2 (]: Writing runtime sql for node "model.elt_assignment.customers_raw"
[0m18:04:46.901407 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:04:46.901608 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: BEGIN
[0m18:04:46.901764 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m18:04:46.902110 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:04:46.902291 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: BEGIN
[0m18:04:46.902436 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:04:46.913153 [debug] [Thread-2 (]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.913466 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m18:04:46.913715 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:04:46.914040 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:04:46.914258 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */

  
    

  create  table "staging"."public_bronze"."customers_raw__dbt_tmp"
  
  
    as
  
  (
    -- Reference table created directly by Airflow/SQL COPY
-- dbt will just treat this as a source, not transform
select * from bronze.customers_raw
  );
  
[0m18:04:46.914509 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */

  
    

  create  table "staging"."public_silver"."customers_clean__dbt_tmp"
  
  
    as
  
  (
    WITH b AS (
  SELECT
    customerid,
    age,
    gender,
    tenure,
    monthlycharges,
    contracttype,
    internetservice,
    totalcharges,
    techsupport,
    churn
  FROM bronze.customers_raw
)
SELECT
  md5((customerid)::text) AS customer_hash,
  COALESCE(NULLIF(LOWER(gender), ''), 'unknown')   AS gender,
  COALESCE((age)::int, 0)                          AS age,
  GREATEST(COALESCE((tenure)::int, 0), 0)          AS tenure_months,
  COALESCE((monthlycharges)::numeric(10,2), 0.00)  AS monthly_charges,
  COALESCE(NULLIF(contracttype, ''), 'Unknown')    AS contract_type,
  COALESCE(NULLIF(internetservice, ''), 'Unknown') AS internet_service,
  COALESCE((totalcharges)::numeric(12,2), 0.00)    AS total_charges,
  CASE 
    WHEN LOWER(COALESCE(techsupport, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(techsupport, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS has_tech_support,
  CASE 
    WHEN LOWER(COALESCE(churn, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(churn, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS is_churned,
  CURRENT_TIMESTAMP                                  AS _loaded_at
FROM b
  );
  
[0m18:04:46.918552 [debug] [Thread-2 (]: SQL status: SELECT 1000 in 0.004 seconds
[0m18:04:46.923224 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:04:46.923416 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.009 seconds
[0m18:04:46.923623 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."public_bronze"."customers_raw__dbt_tmp" rename to "customers_raw"
[0m18:04:46.925101 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:04:46.925312 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
alter table "staging"."public_silver"."customers_clean__dbt_tmp" rename to "customers_clean"
[0m18:04:46.925722 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:04:46.925874 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:04:46.932254 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:04:46.932844 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:04:46.933023 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:04:46.933185 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:04:46.933328 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:04:46.933467 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:04:46.935259 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m18:04:46.935489 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m18:04:46.938350 [debug] [Thread-1 (]: Applying DROP to: "staging"."public_silver"."customers_clean__dbt_backup"
[0m18:04:46.939480 [debug] [Thread-2 (]: Applying DROP to: "staging"."public_bronze"."customers_raw__dbt_backup"
[0m18:04:46.941734 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:04:46.942073 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:04:46.942257 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
drop table if exists "staging"."public_silver"."customers_clean__dbt_backup" cascade
[0m18:04:46.942445 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
drop table if exists "staging"."public_bronze"."customers_raw__dbt_backup" cascade
[0m18:04:46.943060 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m18:04:46.943221 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m18:04:46.944387 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: Close
[0m18:04:46.944990 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: Close
[0m18:04:46.946449 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf8350>]}
[0m18:04:46.946683 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9e0503d-ae4a-4faf-aaad-6aee26304514', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ad5a90>]}
[0m18:04:46.947075 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_bronze.customers_raw .................. [[32mSELECT 1000[0m in 0.07s]
[0m18:04:46.947409 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_silver.customers_clean ................ [[32mSELECT 1000[0m in 0.07s]
[0m18:04:46.947688 [debug] [Thread-2 (]: Finished running node model.elt_assignment.customers_raw
[0m18:04:46.947908 [debug] [Thread-1 (]: Finished running node model.elt_assignment.customers_clean
[0m18:04:46.948662 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.948842 [debug] [MainThread]: On master: BEGIN
[0m18:04:46.948971 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:04:46.955512 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m18:04:46.955733 [debug] [MainThread]: On master: COMMIT
[0m18:04:46.955876 [debug] [MainThread]: Using postgres connection "master"
[0m18:04:46.956004 [debug] [MainThread]: On master: COMMIT
[0m18:04:46.956502 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:04:46.956738 [debug] [MainThread]: On master: Close
[0m18:04:46.956972 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:04:46.957114 [debug] [MainThread]: Connection 'model.elt_assignment.customers_clean' was properly closed.
[0m18:04:46.957234 [debug] [MainThread]: Connection 'model.elt_assignment.customers_raw' was properly closed.
[0m18:04:46.957410 [info ] [MainThread]: 
[0m18:04:46.957567 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 0.26 seconds (0.26s).
[0m18:04:46.957934 [debug] [MainThread]: Command end result
[0m18:04:46.971360 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:04:46.981460 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:04:46.985213 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/run_results.json
[0m18:04:46.985424 [info ] [MainThread]: 
[0m18:04:46.985609 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:04:46.985747 [info ] [MainThread]: 
[0m18:04:46.985900 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m18:04:46.988628 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.2891656, "process_in_blocks": "0", "process_kernel_time": 0.336757, "process_mem_max_rss": "136380416", "process_out_blocks": "0", "process_user_time": 1.447131}
[0m18:04:46.988933 [debug] [MainThread]: Command `dbt run` succeeded at 18:04:46.988894 after 1.29 seconds
[0m18:04:46.989124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b7450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10451ccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1015861d0>]}
[0m18:04:46.989308 [debug] [MainThread]: Flushing usage events
[0m18:04:48.765299 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:09:08.263186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f77690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183d6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1183d72d0>]}


============================== 18:09:08.266431 | 7efea014-2dad-4790-be6a-9946c46f6f20 ==============================
[0m18:09:08.266431 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:09:08.266759 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'log_format': 'default', 'introspect': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'indirect_selection': 'eager', 'use_colors': 'True', 'static_parser': 'True', 'empty': 'None', 'partial_parse': 'True', 'quiet': 'False', 'debug': 'False', 'write_json': 'True', 'printer_width': '80', 'warn_error': 'None', 'invocation_command': 'dbt debug'}
[0m18:09:08.280423 [info ] [MainThread]: dbt version: 1.10.10
[0m18:09:08.280708 [info ] [MainThread]: python version: 3.11.5
[0m18:09:08.280886 [info ] [MainThread]: python path: /Users/dhananjayhawal/anaconda3/bin/python
[0m18:09:08.281037 [info ] [MainThread]: os info: macOS-15.6-arm64-arm-64bit
[0m18:09:08.335282 [info ] [MainThread]: Using profiles dir at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt
[0m18:09:08.335574 [info ] [MainThread]: Using profiles.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/profiles.yml
[0m18:09:08.335722 [info ] [MainThread]: Using dbt_project.yml file at /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/dbt_project.yml
[0m18:09:08.336322 [info ] [MainThread]: adapter type: postgres
[0m18:09:08.336459 [info ] [MainThread]: adapter version: 1.8.2
[0m18:09:08.390861 [info ] [MainThread]: Configuration:
[0m18:09:08.391173 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m18:09:08.391312 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m18:09:08.391485 [info ] [MainThread]: Required dependencies:
[0m18:09:08.392014 [debug] [MainThread]: Executing "git --help"
[0m18:09:08.428113 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m18:09:08.428719 [debug] [MainThread]: STDERR: "b''"
[0m18:09:08.428907 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m18:09:08.429097 [info ] [MainThread]: Connection:
[0m18:09:08.429278 [info ] [MainThread]:   host: localhost
[0m18:09:08.429400 [info ] [MainThread]:   port: 5432
[0m18:09:08.429520 [info ] [MainThread]:   user: postgres
[0m18:09:08.429644 [info ] [MainThread]:   database: staging
[0m18:09:08.429762 [info ] [MainThread]:   schema: public
[0m18:09:08.429877 [info ] [MainThread]:   connect_timeout: 10
[0m18:09:08.429990 [info ] [MainThread]:   role: None
[0m18:09:08.430107 [info ] [MainThread]:   search_path: None
[0m18:09:08.430219 [info ] [MainThread]:   keepalives_idle: 0
[0m18:09:08.430330 [info ] [MainThread]:   sslmode: None
[0m18:09:08.430442 [info ] [MainThread]:   sslcert: None
[0m18:09:08.430551 [info ] [MainThread]:   sslkey: None
[0m18:09:08.430659 [info ] [MainThread]:   sslrootcert: None
[0m18:09:08.430776 [info ] [MainThread]:   application_name: dbt
[0m18:09:08.430887 [info ] [MainThread]:   retries: 1
[0m18:09:08.431197 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:09:08.479442 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m18:09:08.529198 [debug] [MainThread]: Using postgres connection "debug"
[0m18:09:08.529428 [debug] [MainThread]: On debug: select 1 as id
[0m18:09:08.529567 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:09:08.565965 [debug] [MainThread]: SQL status: SELECT 1 in 0.036 seconds
[0m18:09:08.566554 [debug] [MainThread]: On debug: Close
[0m18:09:08.566734 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m18:09:08.566901 [info ] [MainThread]: [32mAll checks passed![0m
[0m18:09:08.570229 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.359288, "process_in_blocks": "0", "process_kernel_time": 0.262859, "process_mem_max_rss": "125272064", "process_out_blocks": "0", "process_user_time": 0.789935}
[0m18:09:08.570578 [debug] [MainThread]: Command `dbt debug` succeeded at 18:09:08.570522 after 0.36 seconds
[0m18:09:08.570763 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m18:09:08.570956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x118fe9410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192b05d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10153dd50>]}
[0m18:09:08.571175 [debug] [MainThread]: Flushing usage events
[0m18:09:10.257306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:09:36.410030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e76e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11074fb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f13c10>]}


============================== 18:09:36.414266 | b88bcfa1-5883-47c0-b1a2-3914e98d0a78 ==============================
[0m18:09:36.414266 [info ] [MainThread]: Running with dbt=1.10.10
[0m18:09:36.414607 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run', 'partial_parse': 'True', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'log_cache_events': 'False', 'no_print': 'None', 'static_parser': 'True', 'debug': 'False', 'fail_fast': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'empty': 'False', 'introspect': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_format': 'default', 'write_json': 'True', 'printer_width': '80', 'target_path': 'None'}
[0m18:09:36.740142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f3dbd0>]}
[0m18:09:36.776195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10697cb90>]}
[0m18:09:36.778213 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m18:09:36.831878 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m18:09:36.875716 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m18:09:36.876091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e06d0>]}
[0m18:09:37.346827 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.elt_assignment.gold
[0m18:09:37.349086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a08410>]}
[0m18:09:37.374689 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:09:37.376709 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:09:37.394020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e91350>]}
[0m18:09:37.394333 [info ] [MainThread]: Found 2 models, 434 macros
[0m18:09:37.394505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a1bb10>]}
[0m18:09:37.395179 [info ] [MainThread]: 
[0m18:09:37.395346 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:09:37.395471 [info ] [MainThread]: 
[0m18:09:37.395699 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:09:37.397571 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:09:37.397824 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m18:09:37.468499 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:09:37.468765 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:09:37.468907 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:09:37.469929 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m18:09:37.470118 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m18:09:37.470262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:09:37.504983 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.035 seconds
[0m18:09:37.505231 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.036 seconds
[0m18:09:37.505940 [debug] [ThreadPool]: On list_staging: Close
[0m18:09:37.506448 [debug] [ThreadPool]: On list_staging: Close
[0m18:09:37.507230 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bronze)
[0m18:09:37.507507 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_silver)
[0m18:09:37.510352 [debug] [ThreadPool]: Using postgres connection "list_staging_bronze"
[0m18:09:37.511328 [debug] [ThreadPool]: Using postgres connection "list_staging_silver"
[0m18:09:37.511482 [debug] [ThreadPool]: On list_staging_bronze: BEGIN
[0m18:09:37.511612 [debug] [ThreadPool]: On list_staging_silver: BEGIN
[0m18:09:37.511730 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:09:37.511852 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:09:37.518821 [debug] [ThreadPool]: SQL status: BEGIN in 0.007 seconds
[0m18:09:37.519066 [debug] [ThreadPool]: Using postgres connection "list_staging_silver"
[0m18:09:37.519222 [debug] [ThreadPool]: On list_staging_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_silver"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m18:09:37.521439 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m18:09:37.521606 [debug] [ThreadPool]: Using postgres connection "list_staging_bronze"
[0m18:09:37.521761 [debug] [ThreadPool]: On list_staging_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_bronze"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m18:09:37.521989 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.003 seconds
[0m18:09:37.522682 [debug] [ThreadPool]: On list_staging_silver: ROLLBACK
[0m18:09:37.523184 [debug] [ThreadPool]: On list_staging_silver: Close
[0m18:09:37.523984 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.002 seconds
[0m18:09:37.524641 [debug] [ThreadPool]: On list_staging_bronze: ROLLBACK
[0m18:09:37.525091 [debug] [ThreadPool]: On list_staging_bronze: Close
[0m18:09:37.527532 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.527758 [debug] [MainThread]: On master: BEGIN
[0m18:09:37.527888 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:09:37.534603 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m18:09:37.534841 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.535045 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:09:37.542922 [debug] [MainThread]: SQL status: SELECT 29 in 0.008 seconds
[0m18:09:37.543780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11509ced0>]}
[0m18:09:37.544047 [debug] [MainThread]: On master: ROLLBACK
[0m18:09:37.544756 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.544974 [debug] [MainThread]: On master: BEGIN
[0m18:09:37.545705 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:09:37.545875 [debug] [MainThread]: On master: COMMIT
[0m18:09:37.546016 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.546142 [debug] [MainThread]: On master: COMMIT
[0m18:09:37.546528 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:09:37.546688 [debug] [MainThread]: On master: Close
[0m18:09:37.551911 [debug] [Thread-1 (]: Began running node model.elt_assignment.customers_clean
[0m18:09:37.552122 [debug] [Thread-2 (]: Began running node model.elt_assignment.customers_raw
[0m18:09:37.552355 [info ] [Thread-1 (]: 1 of 2 START sql table model silver.customers_clean ............................ [RUN]
[0m18:09:37.552603 [info ] [Thread-2 (]: 2 of 2 START sql table model bronze.customers_raw .............................. [RUN]
[0m18:09:37.552831 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_bronze, now model.elt_assignment.customers_clean)
[0m18:09:37.553016 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_staging_silver, now model.elt_assignment.customers_raw)
[0m18:09:37.553173 [debug] [Thread-1 (]: Began compiling node model.elt_assignment.customers_clean
[0m18:09:37.553313 [debug] [Thread-2 (]: Began compiling node model.elt_assignment.customers_raw
[0m18:09:37.556543 [debug] [Thread-1 (]: Writing injected SQL for node "model.elt_assignment.customers_clean"
[0m18:09:37.557433 [debug] [Thread-2 (]: Writing injected SQL for node "model.elt_assignment.customers_raw"
[0m18:09:37.558490 [debug] [Thread-1 (]: Began executing node model.elt_assignment.customers_clean
[0m18:09:37.564876 [debug] [Thread-2 (]: Began executing node model.elt_assignment.customers_raw
[0m18:09:37.576328 [debug] [Thread-1 (]: Writing runtime sql for node "model.elt_assignment.customers_clean"
[0m18:09:37.578082 [debug] [Thread-2 (]: Writing runtime sql for node "model.elt_assignment.customers_raw"
[0m18:09:37.579302 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.579477 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: BEGIN
[0m18:09:37.579623 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m18:09:37.579796 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:09:37.580038 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: BEGIN
[0m18:09:37.580180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:09:37.592671 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m18:09:37.593020 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m18:09:37.593294 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.593511 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:09:37.593691 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */

  
    

  create  table "staging"."bronze"."customers_raw__dbt_tmp"
  
  
    as
  
  (
    -- Reference table created directly by Airflow/SQL COPY
-- dbt will just treat this as a source, not transform
select * from bronze.customers_raw
  );
  
[0m18:09:37.593907 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */

  
    

  create  table "staging"."silver"."customers_clean__dbt_tmp"
  
  
    as
  
  (
    WITH b AS (
  SELECT
    customerid,
    age,
    gender,
    tenure,
    monthlycharges,
    contracttype,
    internetservice,
    totalcharges,
    techsupport,
    churn
  FROM bronze.customers_raw
)
SELECT
  md5((customerid)::text) AS customer_hash,
  COALESCE(NULLIF(LOWER(gender), ''), 'unknown')   AS gender,
  COALESCE((age)::int, 0)                          AS age,
  GREATEST(COALESCE((tenure)::int, 0), 0)          AS tenure_months,
  COALESCE((monthlycharges)::numeric(10,2), 0.00)  AS monthly_charges,
  COALESCE(NULLIF(contracttype, ''), 'Unknown')    AS contract_type,
  COALESCE(NULLIF(internetservice, ''), 'Unknown') AS internet_service,
  COALESCE((totalcharges)::numeric(12,2), 0.00)    AS total_charges,
  CASE 
    WHEN LOWER(COALESCE(techsupport, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(techsupport, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS has_tech_support,
  CASE 
    WHEN LOWER(COALESCE(churn, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(churn, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS is_churned,
  CURRENT_TIMESTAMP                                  AS _loaded_at
FROM b
  );
  
[0m18:09:37.598234 [debug] [Thread-2 (]: SQL status: SELECT 1000 in 0.004 seconds
[0m18:09:37.603954 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.604158 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.010 seconds
[0m18:09:37.604363 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."bronze"."customers_raw" rename to "customers_raw__dbt_backup"
[0m18:09:37.605731 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:09:37.605947 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
alter table "staging"."silver"."customers_clean__dbt_tmp" rename to "customers_clean"
[0m18:09:37.606435 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m18:09:37.612690 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:09:37.612978 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:09:37.613156 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m18:09:37.615659 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m18:09:37.615884 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.010 seconds
[0m18:09:37.619271 [debug] [Thread-1 (]: Applying DROP to: "staging"."silver"."customers_clean__dbt_backup"
[0m18:09:37.620821 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.623499 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m18:09:37.623739 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."bronze"."customers_raw__dbt_tmp" rename to "customers_raw"
[0m18:09:37.623997 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
drop table if exists "staging"."silver"."customers_clean__dbt_backup" cascade
[0m18:09:37.624941 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:09:37.625116 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m18:09:37.626791 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:09:37.627996 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: Close
[0m18:09:37.628211 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.628413 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m18:09:37.629823 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112313210>]}
[0m18:09:37.630071 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m18:09:37.631816 [debug] [Thread-2 (]: Applying DROP to: "staging"."bronze"."customers_raw__dbt_backup"
[0m18:09:37.630516 [info ] [Thread-1 (]: 1 of 2 OK created sql table model silver.customers_clean ....................... [[32mSELECT 1000[0m in 0.08s]
[0m18:09:37.632145 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m18:09:37.632405 [debug] [Thread-1 (]: Finished running node model.elt_assignment.customers_clean
[0m18:09:37.632580 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
drop table if exists "staging"."bronze"."customers_raw__dbt_backup" cascade
[0m18:09:37.635631 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m18:09:37.636357 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: Close
[0m18:09:37.636642 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b88bcfa1-5883-47c0-b1a2-3914e98d0a78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fe69d0>]}
[0m18:09:37.636960 [info ] [Thread-2 (]: 2 of 2 OK created sql table model bronze.customers_raw ......................... [[32mSELECT 1000[0m in 0.08s]
[0m18:09:37.637288 [debug] [Thread-2 (]: Finished running node model.elt_assignment.customers_raw
[0m18:09:37.637986 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.638196 [debug] [MainThread]: On master: BEGIN
[0m18:09:37.638345 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:09:37.644960 [debug] [MainThread]: SQL status: BEGIN in 0.007 seconds
[0m18:09:37.645284 [debug] [MainThread]: On master: COMMIT
[0m18:09:37.645426 [debug] [MainThread]: Using postgres connection "master"
[0m18:09:37.645546 [debug] [MainThread]: On master: COMMIT
[0m18:09:37.645925 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:09:37.646098 [debug] [MainThread]: On master: Close
[0m18:09:37.646327 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:09:37.646459 [debug] [MainThread]: Connection 'model.elt_assignment.customers_clean' was properly closed.
[0m18:09:37.646604 [debug] [MainThread]: Connection 'model.elt_assignment.customers_raw' was properly closed.
[0m18:09:37.646785 [info ] [MainThread]: 
[0m18:09:37.646980 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 0.25 seconds (0.25s).
[0m18:09:37.647386 [debug] [MainThread]: Command end result
[0m18:09:37.658301 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m18:09:37.660625 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m18:09:37.664025 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/run_results.json
[0m18:09:37.664254 [info ] [MainThread]: 
[0m18:09:37.664457 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:09:37.664598 [info ] [MainThread]: 
[0m18:09:37.664751 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m18:09:37.667642 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3046299, "process_in_blocks": "0", "process_kernel_time": 0.324821, "process_mem_max_rss": "134299648", "process_out_blocks": "0", "process_user_time": 1.43568}
[0m18:09:37.667945 [debug] [MainThread]: Command `dbt run` succeeded at 18:09:37.667902 after 1.31 seconds
[0m18:09:37.668140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111eb69d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105029090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f92dd0>]}
[0m18:09:37.668308 [debug] [MainThread]: Flushing usage events
[0m18:09:39.336676 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:25:03.646817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cce83d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd13290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd13990>]}


============================== 20:25:03.650827 | 17c37f05-1da8-4e3f-a6a3-707b002ef19a ==============================
[0m20:25:03.650827 [info ] [MainThread]: Running with dbt=1.10.10
[0m20:25:03.651228 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/logs', 'use_colors': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt', 'printer_width': '80', 'empty': 'False', 'target_path': 'None', 'debug': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'quiet': 'False', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error': 'None', 'version_check': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'introspect': 'True'}
[0m20:25:04.011928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d055f50>]}
[0m20:25:04.055575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b10bd0>]}
[0m20:25:04.056890 [info ] [MainThread]: Registered adapter: postgres=1.8.2
[0m20:25:04.121798 [debug] [MainThread]: checksum: 502a0dc23e9052e1ae09f7c44ee219ef7a02dfea7e7d66580d54c304c14d553b, vars: {}, profile: , target: , version: 1.10.10
[0m20:25:04.226054 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m20:25:04.226444 [debug] [MainThread]: Partial parsing: added file: elt_assignment://models/gold/dim_customers.sql
[0m20:25:04.392993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e253790>]}
[0m20:25:04.425868 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m20:25:04.429078 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m20:25:04.449470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3ff090>]}
[0m20:25:04.449812 [info ] [MainThread]: Found 3 models, 434 macros
[0m20:25:04.450026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d15e910>]}
[0m20:25:04.450854 [info ] [MainThread]: 
[0m20:25:04.451062 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:25:04.451219 [info ] [MainThread]: 
[0m20:25:04.451504 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:25:04.453778 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m20:25:04.454107 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m20:25:04.460519 [debug] [ThreadPool]: Acquiring new postgres connection 'list_staging'
[0m20:25:04.568101 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m20:25:04.568366 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m20:25:04.568577 [debug] [ThreadPool]: Using postgres connection "list_staging"
[0m20:25:04.568800 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m20:25:04.568979 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m20:25:04.569146 [debug] [ThreadPool]: On list_staging: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging"} */

    select distinct nspname from pg_namespace
  
[0m20:25:04.569307 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:04.569464 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:04.569613 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:04.729891 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.160 seconds
[0m20:25:04.730375 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.161 seconds
[0m20:25:04.730687 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.161 seconds
[0m20:25:04.731615 [debug] [ThreadPool]: On list_staging: Close
[0m20:25:04.732369 [debug] [ThreadPool]: On list_staging: Close
[0m20:25:04.732997 [debug] [ThreadPool]: On list_staging: Close
[0m20:25:04.734374 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_silver)
[0m20:25:04.734704 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_bronze)
[0m20:25:04.735032 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_staging, now list_staging_gold)
[0m20:25:04.738624 [debug] [ThreadPool]: Using postgres connection "list_staging_silver"
[0m20:25:04.739823 [debug] [ThreadPool]: Using postgres connection "list_staging_bronze"
[0m20:25:04.740899 [debug] [ThreadPool]: Using postgres connection "list_staging_gold"
[0m20:25:04.741085 [debug] [ThreadPool]: On list_staging_silver: BEGIN
[0m20:25:04.741247 [debug] [ThreadPool]: On list_staging_bronze: BEGIN
[0m20:25:04.741397 [debug] [ThreadPool]: On list_staging_gold: BEGIN
[0m20:25:04.741549 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:25:04.741713 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:25:04.741860 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:25:04.752665 [debug] [ThreadPool]: SQL status: BEGIN in 0.011 seconds
[0m20:25:04.752939 [debug] [ThreadPool]: Using postgres connection "list_staging_gold"
[0m20:25:04.753139 [debug] [ThreadPool]: On list_staging_gold: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_gold"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'gold'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'gold'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'gold'
  
[0m20:25:04.757271 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:25:04.758017 [debug] [ThreadPool]: On list_staging_gold: ROLLBACK
[0m20:25:04.758527 [debug] [ThreadPool]: On list_staging_gold: Close
[0m20:25:09.767178 [debug] [ThreadPool]: SQL status: BEGIN in 5.025 seconds
[0m20:25:09.767940 [debug] [ThreadPool]: SQL status: BEGIN in 5.026 seconds
[0m20:25:09.768649 [debug] [ThreadPool]: Using postgres connection "list_staging_silver"
[0m20:25:09.769011 [debug] [ThreadPool]: Using postgres connection "list_staging_bronze"
[0m20:25:09.769402 [debug] [ThreadPool]: On list_staging_silver: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_silver"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'silver'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'silver'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'silver'
  
[0m20:25:09.769961 [debug] [ThreadPool]: On list_staging_bronze: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "list_staging_bronze"} */
select
      'staging' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'bronze'
    union all
    select
      'staging' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'bronze'
    union all
    select
      'staging' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'bronze'
  
[0m20:25:09.775879 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m20:25:09.776419 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m20:25:09.777927 [debug] [ThreadPool]: On list_staging_silver: ROLLBACK
[0m20:25:09.779107 [debug] [ThreadPool]: On list_staging_bronze: ROLLBACK
[0m20:25:09.780077 [debug] [ThreadPool]: On list_staging_bronze: Close
[0m20:25:09.780362 [debug] [ThreadPool]: On list_staging_silver: Close
[0m20:25:09.786286 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.786709 [debug] [MainThread]: On master: BEGIN
[0m20:25:09.786969 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:25:09.799815 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m20:25:09.800262 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.800639 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:25:09.812907 [debug] [MainThread]: SQL status: SELECT 29 in 0.012 seconds
[0m20:25:09.814501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e252190>]}
[0m20:25:09.814988 [debug] [MainThread]: On master: ROLLBACK
[0m20:25:09.815715 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.815988 [debug] [MainThread]: On master: BEGIN
[0m20:25:09.817077 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:25:09.817303 [debug] [MainThread]: On master: COMMIT
[0m20:25:09.817508 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.817695 [debug] [MainThread]: On master: COMMIT
[0m20:25:09.818428 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:25:09.818877 [debug] [MainThread]: On master: Close
[0m20:25:09.824656 [debug] [Thread-1 (]: Began running node model.elt_assignment.customers_clean
[0m20:25:09.825068 [debug] [Thread-2 (]: Began running node model.elt_assignment.customers_raw
[0m20:25:09.825585 [info ] [Thread-1 (]: 1 of 3 START sql table model silver.customers_clean ............................ [RUN]
[0m20:25:09.826345 [info ] [Thread-2 (]: 2 of 3 START sql table model bronze.customers_raw .............................. [RUN]
[0m20:25:09.826828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_staging_silver, now model.elt_assignment.customers_clean)
[0m20:25:09.827158 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_staging_bronze, now model.elt_assignment.customers_raw)
[0m20:25:09.827466 [debug] [Thread-1 (]: Began compiling node model.elt_assignment.customers_clean
[0m20:25:09.827760 [debug] [Thread-2 (]: Began compiling node model.elt_assignment.customers_raw
[0m20:25:09.833364 [debug] [Thread-1 (]: Writing injected SQL for node "model.elt_assignment.customers_clean"
[0m20:25:09.834981 [debug] [Thread-2 (]: Writing injected SQL for node "model.elt_assignment.customers_raw"
[0m20:25:09.836048 [debug] [Thread-2 (]: Began executing node model.elt_assignment.customers_raw
[0m20:25:09.836311 [debug] [Thread-1 (]: Began executing node model.elt_assignment.customers_clean
[0m20:25:09.866446 [debug] [Thread-1 (]: Writing runtime sql for node "model.elt_assignment.customers_clean"
[0m20:25:09.866981 [debug] [Thread-2 (]: Writing runtime sql for node "model.elt_assignment.customers_raw"
[0m20:25:09.868206 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m20:25:09.868493 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.868695 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: BEGIN
[0m20:25:09.868967 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: BEGIN
[0m20:25:09.869216 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:25:09.869411 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:25:09.877284 [debug] [Thread-2 (]: SQL status: BEGIN in 0.008 seconds
[0m20:25:09.877615 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.877853 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */

  
    

  create  table "staging"."bronze"."customers_raw__dbt_tmp"
  
  
    as
  
  (
    -- Reference table created directly by Airflow/SQL COPY
-- dbt will just treat this as a source, not transform
select * from bronze.customers_raw
  );
  
[0m20:25:09.880139 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m20:25:09.880439 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m20:25:09.880709 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */

  
    

  create  table "staging"."silver"."customers_clean__dbt_tmp"
  
  
    as
  
  (
    WITH b AS (
  SELECT
    customerid,
    age,
    gender,
    tenure,
    monthlycharges,
    contracttype,
    internetservice,
    totalcharges,
    techsupport,
    churn
  FROM bronze.customers_raw
)
SELECT
  md5((customerid)::text) AS customer_hash,
  COALESCE(NULLIF(LOWER(gender), ''), 'unknown')   AS gender,
  COALESCE((age)::int, 0)                          AS age,
  GREATEST(COALESCE((tenure)::int, 0), 0)          AS tenure_months,
  COALESCE((monthlycharges)::numeric(10,2), 0.00)  AS monthly_charges,
  COALESCE(NULLIF(contracttype, ''), 'Unknown')    AS contract_type,
  COALESCE(NULLIF(internetservice, ''), 'Unknown') AS internet_service,
  COALESCE((totalcharges)::numeric(12,2), 0.00)    AS total_charges,
  CASE 
    WHEN LOWER(COALESCE(techsupport, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(techsupport, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS has_tech_support,
  CASE 
    WHEN LOWER(COALESCE(churn, '')) = 'yes' THEN TRUE
    WHEN LOWER(COALESCE(churn, '')) = 'no'  THEN FALSE
    ELSE NULL
  END                                                AS is_churned,
  CURRENT_TIMESTAMP                                  AS _loaded_at
FROM b
  );
  
[0m20:25:09.881910 [debug] [Thread-2 (]: SQL status: SELECT 1000 in 0.004 seconds
[0m20:25:09.887905 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.888193 [debug] [Thread-1 (]: SQL status: SELECT 1000 in 0.007 seconds
[0m20:25:09.888409 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."bronze"."customers_raw" rename to "customers_raw__dbt_backup"
[0m20:25:09.890209 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m20:25:09.890480 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
alter table "staging"."silver"."customers_clean__dbt_tmp" rename to "customers_clean"
[0m20:25:09.891157 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:25:09.899220 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m20:25:09.899473 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m20:25:09.899673 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: COMMIT
[0m20:25:09.901630 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m20:25:09.901885 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.011 seconds
[0m20:25:09.905507 [debug] [Thread-1 (]: Applying DROP to: "staging"."silver"."customers_clean__dbt_backup"
[0m20:25:09.907268 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.910032 [debug] [Thread-1 (]: Using postgres connection "model.elt_assignment.customers_clean"
[0m20:25:09.910279 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
alter table "staging"."bronze"."customers_raw__dbt_tmp" rename to "customers_raw"
[0m20:25:09.910505 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_clean"} */
drop table if exists "staging"."silver"."customers_clean__dbt_backup" cascade
[0m20:25:09.911298 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:25:09.911579 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:25:09.913477 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m20:25:09.914834 [debug] [Thread-1 (]: On model.elt_assignment.customers_clean: Close
[0m20:25:09.915070 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.915350 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: COMMIT
[0m20:25:09.916993 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m20:25:09.918441 [debug] [Thread-2 (]: Applying DROP to: "staging"."bronze"."customers_raw__dbt_backup"
[0m20:25:09.918756 [debug] [Thread-2 (]: Using postgres connection "model.elt_assignment.customers_raw"
[0m20:25:09.918965 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.customers_raw"} */
drop table if exists "staging"."bronze"."customers_raw__dbt_backup" cascade
[0m20:25:09.919188 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebdb10>]}
[0m20:25:09.919594 [info ] [Thread-1 (]: 1 of 3 OK created sql table model silver.customers_clean ....................... [[32mSELECT 1000[0m in 0.09s]
[0m20:25:09.919921 [debug] [Thread-1 (]: Finished running node model.elt_assignment.customers_clean
[0m20:25:09.920251 [debug] [Thread-4 (]: Began running node model.elt_assignment.dim_customers
[0m20:25:09.920534 [info ] [Thread-4 (]: 3 of 3 START sql table model gold.dim_customers ................................ [RUN]
[0m20:25:09.920855 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.elt_assignment.dim_customers'
[0m20:25:09.921061 [debug] [Thread-4 (]: Began compiling node model.elt_assignment.dim_customers
[0m20:25:09.922771 [debug] [Thread-4 (]: Writing injected SQL for node "model.elt_assignment.dim_customers"
[0m20:25:09.923013 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.004 seconds
[0m20:25:09.923838 [debug] [Thread-2 (]: On model.elt_assignment.customers_raw: Close
[0m20:25:09.924177 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d057990>]}
[0m20:25:09.924610 [info ] [Thread-2 (]: 2 of 3 OK created sql table model bronze.customers_raw ......................... [[32mSELECT 1000[0m in 0.10s]
[0m20:25:09.924935 [debug] [Thread-2 (]: Finished running node model.elt_assignment.customers_raw
[0m20:25:09.925148 [debug] [Thread-4 (]: Began executing node model.elt_assignment.dim_customers
[0m20:25:09.927194 [debug] [Thread-4 (]: Writing runtime sql for node "model.elt_assignment.dim_customers"
[0m20:25:09.928217 [debug] [Thread-4 (]: Using postgres connection "model.elt_assignment.dim_customers"
[0m20:25:09.928414 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: BEGIN
[0m20:25:09.928589 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:25:09.937266 [debug] [Thread-4 (]: SQL status: BEGIN in 0.009 seconds
[0m20:25:09.937536 [debug] [Thread-4 (]: Using postgres connection "model.elt_assignment.dim_customers"
[0m20:25:09.937745 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.dim_customers"} */

  
    

  create  table "staging"."gold"."dim_customers__dbt_tmp"
  
  
    as
  
  (
    -- Gold dimension: anonymized customers with cleaned attributes

SELECT
  customer_hash,
  gender,
  age,
  tenure_months,
  monthly_charges,
  total_charges,
  contract_type,
  internet_service,
  has_tech_support,
  _loaded_at
FROM "staging"."silver"."customers_clean"
  );
  
[0m20:25:09.942601 [debug] [Thread-4 (]: SQL status: SELECT 1000 in 0.005 seconds
[0m20:25:09.946072 [debug] [Thread-4 (]: Using postgres connection "model.elt_assignment.dim_customers"
[0m20:25:09.946376 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.dim_customers"} */
alter table "staging"."gold"."dim_customers__dbt_tmp" rename to "dim_customers"
[0m20:25:09.947329 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:25:09.948201 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: COMMIT
[0m20:25:09.948443 [debug] [Thread-4 (]: Using postgres connection "model.elt_assignment.dim_customers"
[0m20:25:09.948662 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: COMMIT
[0m20:25:09.950207 [debug] [Thread-4 (]: SQL status: COMMIT in 0.001 seconds
[0m20:25:09.951751 [debug] [Thread-4 (]: Applying DROP to: "staging"."gold"."dim_customers__dbt_backup"
[0m20:25:09.952091 [debug] [Thread-4 (]: Using postgres connection "model.elt_assignment.dim_customers"
[0m20:25:09.952328 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: /* {"app": "dbt", "dbt_version": "1.10.10", "profile_name": "elt_assignment", "target_name": "dev", "node_id": "model.elt_assignment.dim_customers"} */
drop table if exists "staging"."gold"."dim_customers__dbt_backup" cascade
[0m20:25:09.952971 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:25:09.953845 [debug] [Thread-4 (]: On model.elt_assignment.dim_customers: Close
[0m20:25:09.954269 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c37f05-1da8-4e3f-a6a3-707b002ef19a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7dbe50>]}
[0m20:25:09.954682 [info ] [Thread-4 (]: 3 of 3 OK created sql table model gold.dim_customers ........................... [[32mSELECT 1000[0m in 0.03s]
[0m20:25:09.955012 [debug] [Thread-4 (]: Finished running node model.elt_assignment.dim_customers
[0m20:25:09.955850 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.956048 [debug] [MainThread]: On master: BEGIN
[0m20:25:09.956199 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:25:09.964187 [debug] [MainThread]: SQL status: BEGIN in 0.008 seconds
[0m20:25:09.964496 [debug] [MainThread]: On master: COMMIT
[0m20:25:09.964676 [debug] [MainThread]: Using postgres connection "master"
[0m20:25:09.964834 [debug] [MainThread]: On master: COMMIT
[0m20:25:09.965361 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:25:09.965650 [debug] [MainThread]: On master: Close
[0m20:25:09.965930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:25:09.966096 [debug] [MainThread]: Connection 'model.elt_assignment.customers_clean' was properly closed.
[0m20:25:09.966237 [debug] [MainThread]: Connection 'model.elt_assignment.customers_raw' was properly closed.
[0m20:25:09.966373 [debug] [MainThread]: Connection 'list_staging_gold' was properly closed.
[0m20:25:09.966504 [debug] [MainThread]: Connection 'model.elt_assignment.dim_customers' was properly closed.
[0m20:25:09.966726 [info ] [MainThread]: 
[0m20:25:09.966917 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 5.52 seconds (5.52s).
[0m20:25:09.967403 [debug] [MainThread]: Command end result
[0m20:25:09.980028 [debug] [MainThread]: Wrote artifact WritableManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/manifest.json
[0m20:25:09.981986 [debug] [MainThread]: Wrote artifact SemanticManifest to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/semantic_manifest.json
[0m20:25:09.986199 [debug] [MainThread]: Wrote artifact RunExecutionResult to /Users/dhananjayhawal/Documents/GitHub/Open_Source_ETL_Pipelines/dbt/target/run_results.json
[0m20:25:09.986427 [info ] [MainThread]: 
[0m20:25:09.986660 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:25:09.986828 [info ] [MainThread]: 
[0m20:25:09.987004 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m20:25:09.989823 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.4133506, "process_in_blocks": "0", "process_kernel_time": 0.413333, "process_mem_max_rss": "137641984", "process_out_blocks": "0", "process_user_time": 1.551493}
[0m20:25:09.990176 [debug] [MainThread]: Command `dbt run` succeeded at 20:25:09.990119 after 6.41 seconds
[0m20:25:09.990412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd0fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c9cf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c06cd0>]}
[0m20:25:09.990636 [debug] [MainThread]: Flushing usage events
[0m20:25:11.485024 [debug] [MainThread]: An error was encountered while trying to flush usage events
